{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import CIFAR10\n",
    "import numpy as np\n",
    "from torch  import optim\n",
    "import torchvision.utils as vutil\n",
    "from tensorboard_logger import Logger\n",
    "import torchvision as tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    lr=0.0002\n",
    "    nz=100# 噪声维度\n",
    "    image_size=64\n",
    "    image_size2=64\n",
    "    nc=3# 图片三通道\n",
    "    ngf=64 #生成图片\n",
    "    ndf=64 #判别图片\n",
    "    gpuids=2\n",
    "    beta1=0.5\n",
    "    batch_size=1024\n",
    "    max_epoch=12# =1 when debug\n",
    "    workers=4\n",
    "    clamp_num=0.01# WGAN 截断大小\n",
    "    \n",
    "opt=Config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "\n",
    "dataset=tv.datasets.ImageFolder('/home/x/data/pre/train_new/nouse/',\n",
    "                transform=transforms.Compose(\\\n",
    "                                             \n",
    "                                             [transforms.Scale(opt.image_size),\n",
    "                                              transforms.RandomCrop(opt.image_size) ,\n",
    "#                                               transforms.RandomSizedCrop()\n",
    "                                              transforms.ToTensor(),\n",
    "                                              transforms.Normalize([0.5]*3,[0.5]*3)\n",
    "                                             ]))\n",
    "dataloader=t.utils.data.DataLoader(dataset,opt.batch_size,True,num_workers=opt.workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 网络结构\n",
    "\n",
    "class ModelG(nn.Module):\n",
    "    def __init__(self,ngpu):\n",
    "        super(ModelG,self).__init__()\n",
    "        self.ngpu=ngpu\n",
    "        self.model=nn.Sequential()\n",
    "        self.model.add_module('deconv1',nn.ConvTranspose2d(opt.nz,opt.ngf*8,4,1,0,bias=False))\n",
    "        self.model.add_module('bnorm1',nn.BatchNorm2d(opt.ngf*8))\n",
    "        self.model.add_module('relu1',nn.ReLU(True))\n",
    "        self.model.add_module('deconv2',nn.ConvTranspose2d(opt.ngf*8,opt.ngf*4,4,2,1,bias=False))\n",
    "        self.model.add_module('bnorm2',nn.BatchNorm2d(opt.ngf*4))\n",
    "        self.model.add_module('relu2',nn.ReLU(True))\n",
    "        self.model.add_module('deconv3',nn.ConvTranspose2d(opt.ngf*4,opt.ngf*2,4,2,1,bias=False))\n",
    "        self.model.add_module('bnorm3',nn.BatchNorm2d(opt.ngf*2))\n",
    "        self.model.add_module('relu3',nn.ReLU(True))\n",
    "        self.model.add_module('deconv4',nn.ConvTranspose2d(opt.ngf*2,opt.ngf,4,2,1,bias=False))\n",
    "        self.model.add_module('bnorm4',nn.BatchNorm2d(opt.ngf))\n",
    "        self.model.add_module('relu4',nn.ReLU(True))\n",
    "        self.model.add_module('deconv5',nn.ConvTranspose2d(opt.ngf,opt.nc,4,2,1,bias=False))\n",
    "        self.model.add_module('tanh',nn.Tanh())\n",
    "    def forward(self,input):\n",
    "         \n",
    "        if self.ngpu:\n",
    "            gpuids=range(self.ngpu)\n",
    "        return nn.parallel.data_parallel(self.model,input, device_ids=gpuids)\n",
    "\n",
    "def weight_init(m):\n",
    "    # 参数初始化。\n",
    "    class_name=m.__class__.__name__\n",
    "    if class_name.find('conv')!=-1:\n",
    "        m.weight.data.normal_(0,0.02)\n",
    "    if class_name.find('norm')!=-1:\n",
    "        m.weight.data.normal_(1.0,0.02)\n",
    "    \n",
    "class ModelD(nn.Module):\n",
    "    def __init__(self,ngpu):\n",
    "        super(ModelD,self).__init__()\n",
    "        self.ngpu=ngpu\n",
    "        self.model=nn.Sequential()\n",
    "        self.model.add_module('conv1',nn.Conv2d(opt.nc,opt.ndf,4,2,1,bias=False))\n",
    "        self.model.add_module('relu1',nn.LeakyReLU(0.2,inplace=True))\n",
    "        \n",
    "        self.model.add_module('conv2',nn.Conv2d(opt.ndf,opt.ndf*2,4,2,1,bias=False))\n",
    "        self.model.add_module('bnorm2',nn.BatchNorm2d(opt.ndf*2))\n",
    "        self.model.add_module('relu2',nn.LeakyReLU(0.2,inplace=True))\n",
    "        \n",
    "        self.model.add_module('conv3',nn.Conv2d(opt.ndf*2,opt.ndf*4,4,2,1,bias=False))\n",
    "        self.model.add_module('bnorm3',nn.BatchNorm2d(opt.ndf*4))\n",
    "        self.model.add_module('relu3',nn.LeakyReLU(0.2,inplace=True))\n",
    "        \n",
    "        self.model.add_module('conv4',nn.Conv2d(opt.ndf*4,opt.ndf*8,4,2,1,bias=False))\n",
    "        self.model.add_module('bnorm4',nn.BatchNorm2d(opt.ndf*8))\n",
    "        self.model.add_module('relu4',nn.LeakyReLU(0.2,inplace=True))\n",
    "        \n",
    "        self.model.add_module('conv5',nn.Conv2d(opt.ndf*8,1,4,1,0,bias=False))\n",
    "        \n",
    "    def forward(self,input):    \n",
    "        if self.ngpu:\n",
    "            gpuids=range(self.ngpu)\n",
    "        return nn.parallel.data_parallel(self.model,input, device_ids=gpuids).view(-1,1).mean(0).view(1)#\n",
    "         ## no loss but score\n",
    "\n",
    "netg=ModelG(opt.gpuids)\n",
    "netd=ModelD(opt.gpuids)\n",
    "\n",
    "netd.cuda()\n",
    "netg.cuda()\n",
    "\n",
    "netd.apply(weight_init)\n",
    "netg.apply(weight_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义优化器\n",
    "\n",
    "optimizerD=optim.RMSprop(netd.parameters(),lr=opt.lr ) #modify ： 不要采用基于动量的优化方法 如Adam\n",
    "optimizerG=optim.RMSprop(netg.parameters(),lr=opt.lr )  #  \n",
    "\n",
    "# 定义 D网和G网的输入\n",
    "input=Variable(t.FloatTensor(opt.batch_size,opt.nc,opt.image_size,opt.image_size2).cuda())\n",
    "noise=Variable(t.FloatTensor(opt.batch_size,opt.nz,1,1).cuda()) \n",
    "fixed_noise=Variable(t.cuda.FloatTensor(64,opt.nz,1,1).normal_(0,1)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#criterion=nn.BCELoss() # WGAN 不需要log（交叉熵） \n",
    "one=t.FloatTensor([1])\n",
    "mone=-1*one\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "input=Variable(t.FloatTensor(opt.batch_size,opt.nc,opt.image_size,opt.image_size2).cuda())\n",
    "#开始训练\n",
    "input=Variable(t.FloatTensor(opt.batch_size,opt.nc,opt.image_size,opt.image_size2).cuda())\n",
    "for epoch in xrange(150,151):\n",
    "    try:\n",
    "     for ii, data in enumerate(dataloader,0):\n",
    "        #### 训练D网 ####\n",
    "        print ii\n",
    "        netd.zero_grad() #有必要\n",
    "        real,_=data\n",
    "        input.data.resize_(real.size()).copy_(real.cuda())\n",
    "      \n",
    "        output=netd(input)\n",
    "        output.backward(one)#######for wgan\n",
    "        D_x=output.data.mean()\n",
    "        \n",
    "        noise.data.resize_(input.size()[0],opt.nz,1,1 ).normal_(0,1)\n",
    "        fake_pic=netg(noise).detach()\n",
    "        output2=netd(fake_pic)\n",
    "       \n",
    "    \n",
    "        output2.backward(mone) #for wgan\n",
    "        D_x2=output2.data.mean()        \n",
    "        optimizerD.step()\n",
    "        for parm in netd.parameters():parm.data.clamp_(-opt.clamp_num,opt.clamp_num) ### 只有判别器需要 截断参数\n",
    "        \n",
    "        #### 训练G网 ########\n",
    "\n",
    "        if ii%5 :\n",
    "            netg.zero_grad()\n",
    "            noise.data.normal_(0,1)\n",
    "            fake_pic=netg(noise)\n",
    "            output=netd(fake_pic)\n",
    "            output.backward(one)\n",
    "            optimizerG.step()\n",
    "            #for parm in netg.parameters():parm.data.clamp_(-opt.clamp_num,opt.clamp_num)## 只有判别器需要 生成器不需要\n",
    "            D_G_z2=output.data.mean()\n",
    "\n",
    "        if ii%10==0 and ii>0 and False:\n",
    "            fake_u=netg(fixed_noise)\n",
    "            vutil.save_image(fake_u.data,'badgen2/fake%s_%s.png'%(epoch,ii))\n",
    "#             vutil.save_image(real,'wgan/real%s_%s.png'%(epoch,ii)) \n",
    "#             break\n",
    "            print epoch,ii\n",
    "    except Exception as e:\n",
    "        print e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](image/fake.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
