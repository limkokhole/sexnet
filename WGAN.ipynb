{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import CIFAR10\n",
    "import numpy as np\n",
    "from torch  import optim\n",
    "import torchvision.utils as vutil\n",
    "from tensorboard_logger import Logger\n",
    "import torchvision as tv\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "from tensorboard_logger import configure, log_value, Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DefaultConfig:\n",
    "        \n",
    "    # DO NOT MODIFY HERE\n",
    "    lr=2e-4\n",
    "    nz=100# 噪声维度\n",
    "    image_size=64\n",
    "    image_size2=64\n",
    "    nc=3# 图片三通道\n",
    "    ngf=64 #生成图片\n",
    "    ndf=64 #判别图片\n",
    "    gpuids=2 # GPU 数目\n",
    "    beta1=0.5  #\n",
    "    batch_size=256　\n",
    "    max_epoch=120# =1 when debug\n",
    "    workers=4\n",
    "    clamp_num=0.01# WGAN 截断大小\n",
    "class Config(DefaultConfig):\n",
    "    # OVERWRIGHT HERE\n",
    "    pass\n",
    "\n",
    "opt=Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  数据加载\n",
    "class MyImageFolder(ImageFolder):\n",
    "    '''\n",
    "    复写ImageFolder 因为有些图片有问题,\n",
    "    有问题的图片就返回None\n",
    "    '''\n",
    "    __init__ = ImageFolder.__init__\n",
    "    def __getitem__(self, index):\n",
    "        try: \n",
    "            return super(MyImageFolder, self).__getitem__(index) \n",
    "        except Exception as e:\n",
    "            print e\n",
    "\n",
    "val_dataset = MyImageFolder('/home/x/data/pre/train_new/nouse',\n",
    "                transform=transforms.Compose(\\\n",
    "                                             \n",
    "                                             [transforms.Scale(opt.image_size),\n",
    "                                              transforms.RandomCrop(opt.image_size) ,\n",
    "                                              transforms.ToTensor(),\n",
    "                                              transforms.Normalize([0.5]*3,[0.5]*3)\n",
    "                                             ]))\n",
    "\n",
    "def my_collate(batch):\n",
    "    '''\n",
    "    过滤掉为None的数据\n",
    "    '''\n",
    "    batch = filter (lambda x:x is not None, batch)\n",
    "    return default_collate(batch)\n",
    "\n",
    "val_dataloader=t.utils.data.DataLoader(val_dataset,opt.batch_size,True,num_workers=opt.workers, collate_fn=my_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 网络结构 定义 \n",
    "torch = t\n",
    "class DCGAN_G(nn.Module):\n",
    "    def __init__(self, isize, nz, nc, ngf, ngpu, n_extra_layers=0):\n",
    "        super(DCGAN_G, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        assert isize % 16 == 0, \"isize has to be a multiple of 16\"\n",
    "\n",
    "        cngf, tisize = ngf//2, 4\n",
    "        while tisize != isize:\n",
    "            cngf = cngf * 2\n",
    "            tisize = tisize * 2\n",
    "\n",
    "        main = nn.Sequential()\n",
    "        # input is Z, going into a convolution\n",
    "        main.add_module('initial.{0}-{1}.convt'.format(nz, cngf),\n",
    "                        nn.ConvTranspose2d(nz, cngf, 4, 1, 0, bias=False))\n",
    "        main.add_module('initial.{0}.batchnorm'.format(cngf),\n",
    "                        nn.BatchNorm2d(cngf))\n",
    "        main.add_module('initial.{0}.relu'.format(cngf),\n",
    "                        nn.ReLU(True))\n",
    "\n",
    "        csize, cndf = 4, cngf\n",
    "        while csize < isize//2:\n",
    "            main.add_module('pyramid.{0}-{1}.convt'.format(cngf, cngf//2),\n",
    "                            nn.ConvTranspose2d(cngf, cngf//2, 4, 2, 1, bias=False))\n",
    "            main.add_module('pyramid.{0}.batchnorm'.format(cngf//2),\n",
    "                            nn.BatchNorm2d(cngf//2))\n",
    "            main.add_module('pyramid.{0}.relu'.format(cngf//2),\n",
    "                            nn.ReLU(True))\n",
    "            cngf = cngf // 2\n",
    "            csize = csize * 2\n",
    "\n",
    "        # Extra layers\n",
    "        for t in range(n_extra_layers):\n",
    "            main.add_module('extra-layers-{0}.{1}.conv'.format(t, cngf),\n",
    "                            nn.Conv2d(cngf, cngf, 3, 1, 1, bias=False))\n",
    "            main.add_module('extra-layers-{0}.{1}.batchnorm'.format(t, cngf),\n",
    "                            nn.BatchNorm2d(cngf))\n",
    "            main.add_module('extra-layers-{0}.{1}.relu'.format(t, cngf),\n",
    "                            nn.ReLU(True))\n",
    "\n",
    "        main.add_module('final.{0}-{1}.convt'.format(cngf, nc),\n",
    "                        nn.ConvTranspose2d(cngf, nc, 4, 2, 1, bias=False))\n",
    "        main.add_module('final.{0}.tanh'.format(nc),\n",
    "                        nn.Tanh())\n",
    "        self.main = main\n",
    "\n",
    "    def forward(self, input):\n",
    "        gpu_ids = None\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            gpu_ids = range(self.ngpu)\n",
    "        return nn.parallel.data_parallel(self.main, input, gpu_ids)\n",
    "\n",
    "class DCGAN_D(nn.Module):\n",
    "    def __init__(self, isize, nz, nc, ndf, ngpu, n_extra_layers=0):\n",
    "        super(DCGAN_D, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        assert isize % 16 == 0, \"isize has to be a multiple of 16\"\n",
    "\n",
    "        main = nn.Sequential()\n",
    "        # input is nc x isize x isize\n",
    "        main.add_module('initial.conv.{0}-{1}'.format(nc, ndf),\n",
    "                        nn.Conv2d(nc, ndf, 4, 2, 1, bias=False))\n",
    "        main.add_module('initial.relu.{0}'.format(ndf),\n",
    "                        nn.LeakyReLU(0.2, inplace=True))\n",
    "        csize, cndf = isize / 2, ndf\n",
    "\n",
    "        # Extra layers\n",
    "        for t in range(n_extra_layers):\n",
    "            main.add_module('extra-layers-{0}.{1}.conv'.format(t, cndf),\n",
    "                            nn.Conv2d(cndf, cndf, 3, 1, 1, bias=False))\n",
    "            main.add_module('extra-layers-{0}.{1}.batchnorm'.format(t, cndf),\n",
    "                            nn.BatchNorm2d(cndf))\n",
    "            main.add_module('extra-layers-{0}.{1}.relu'.format(t, cndf),\n",
    "                            nn.LeakyReLU(0.2, inplace=True))\n",
    "\n",
    "        while csize > 4:\n",
    "            in_feat = cndf\n",
    "            out_feat = cndf * 2\n",
    "            main.add_module('pyramid.{0}-{1}.conv'.format(in_feat, out_feat),\n",
    "                            nn.Conv2d(in_feat, out_feat, 4, 2, 1, bias=False))\n",
    "            main.add_module('pyramid.{0}.batchnorm'.format(out_feat),\n",
    "                            nn.BatchNorm2d(out_feat))\n",
    "            main.add_module('pyramid.{0}.relu'.format(out_feat),\n",
    "                            nn.LeakyReLU(0.2, inplace=True))\n",
    "            cndf = cndf * 2\n",
    "            csize = csize / 2\n",
    "\n",
    "        # state size. K x 4 x 4\n",
    "        main.add_module('final.{0}-{1}.conv'.format(cndf, 1),\n",
    "                        nn.Conv2d(cndf, 1, 4, 1, 0, bias=False))\n",
    "        self.main = main\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        gpu_ids = None\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            gpu_ids = range(self.ngpu)\n",
    "        output = nn.parallel.data_parallel(self.main, input, gpu_ids)\n",
    "        output = output.mean(0)\n",
    "        return output.view(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netG = DCGAN_G(opt.image_size, opt.nz, opt.nc, opt.ngf, opt.gpuids, 1)\n",
    "netD = DCGAN_D(opt.image_size, opt.nz, opt.nc, opt.ndf,opt.gpuids,1)\n",
    "def weight_init(m):\n",
    "    # 参数初始化。 可以改成xavier初始化方法\n",
    "    class_name=m.__class__.__name__\n",
    "    if class_name.find('Conv')!=-1:       \n",
    "        m.weight.data.normal_(0,0.02)\n",
    "    if class_name.find('Norm')!=-1:\n",
    "        m.weight.data.normal_(1.0,0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "netG.apply(weight_init)\n",
    "netD.apply(weight_init)\n",
    "netG.cuda()\n",
    "netD.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 训练\n",
    "netd = netD\n",
    "netg = netG\n",
    "optimizerD=optim.RMSprop(netd.parameters(),lr=opt.lr*0.1 ) #modify ： 不要采用基于动量的优化方法 如Adam\n",
    "optimizerG=optim.RMSprop(netg.parameters(),lr=opt.lr*0.1 )  #  \n",
    "\n",
    "#criterion=nn.BCELoss() # WGAN 不需要log（交叉熵） \n",
    "one=t.FloatTensor([1])\n",
    "mone=-1*one\n",
    "\n",
    "noise=Variable(t.FloatTensor(opt.batch_size,opt.nz,1,1).cuda()) \n",
    "fixed_noise=Variable(t.cuda.FloatTensor(64,opt.nz,1,1).normal_(0,1)) \n",
    "\n",
    "test_logger = Logger('tensorboard_log/runs/dcsb_4')\n",
    "\n",
    "\n",
    "for epoch in xrange(150,280):\n",
    "    try:\n",
    "     for ii, data in enumerate(val_dataloader,0):\n",
    "        #### 训练D网 ####\n",
    "        if True :\n",
    "            netd.zero_grad() \n",
    "            real,_=data\n",
    "            input=Variable(real).cuda()\n",
    "            output=netd(input)\n",
    "            test_logger.log_value('errorD_real', output.data[0])\n",
    "            output.backward(one)#######for wganut\n",
    "            D_x=output.data.mean()\n",
    "\n",
    "            noise.data.resize_(input.size()[0],opt.nz,1,1 ).normal_(0,1)\n",
    "            #　Volatile = True 可以加快netg的计算, 减少内存占用\n",
    "            fake_pic = netg(Variable(noise.data, volatile = True)) \n",
    "            output2 = netd(Variable(fake_pic.data))\n",
    "            if epoch>0:test_logger.log_value('errorD_fake', output2.data[0])\n",
    "            if epoch>0:test_logger.log_value('errorD_',output.data[0] - output2.data[0])\n",
    "\n",
    "\n",
    "            output2.backward(mone) #for wgan\n",
    "            D_x2=output2.data.mean()        \n",
    "            optimizerD.step()\n",
    "            \n",
    "            test_logger.log_value('D_X2',D_x2) #判别器对假样本的平均给分\n",
    "            if epoch>0:test_logger.log_value('D_x',D_x) #判别器给真图片的平均给分\n",
    "            \n",
    "            for parm in netd.parameters():parm.data.clamp_(-opt.clamp_num,opt.clamp_num) ### WGAN:判别器需要 截断参数\n",
    "\n",
    "\n",
    "        # d网和g网的训练次数不一样, 这里d网和g网的训练比例大概是: 5:1\n",
    "        if ii%5 ==0   :\n",
    "            netg.zero_grad()\n",
    "            noise.data.normal_(0,1)\n",
    "            fake_pic=netg(noise)\n",
    "            output=netd(fake_pic)\n",
    "            output.backward(one)\n",
    "            if epoch>0:test_logger.log_value('error_G',output.data[0])\n",
    "            optimizerG.step()\n",
    "            D_G_z2=output.data.mean()\n",
    "            if epoch>0:test_logger.log_value('D_G_z2', D_G_z2)      \n",
    "\n",
    "        if ii%100==0 and ii>0 and True:\n",
    "            # 保存生成的图片\n",
    "            fake_u=netg(fixed_noise)\n",
    "            vutil.save_image(fake_u.data,'20170306/dcsb/fake1_%s_%s.png'%(epoch,ii))\n",
    "            test_logger.log_value('epoch_ii', ii)\n",
    "#学习率的衰减\n",
    "#      if epoch%50 == 49: \n",
    "#             n__ = epoch/50 -1\n",
    "#             optimizerD=optim.RMSprop(netd.parameters(),lr=opt.lr*(0.1**n__) ) \n",
    "#             optimizerG=optim.RMSprop(netg.parameters(),lr=opt.lr*(0.1**n__) )\n",
    "     t.save(netd.state_dict(),'20170306/bad_netd_%s_epotch.pth' %epoch)\n",
    "     t.save(netg.state_dict(),'20170306/bad_netg_%s_epotch.pth' %epoch)\n",
    "     test_logger.log_value('epoch_n', epoch)\n",
    "     \n",
    "    except Exception as e:\n",
    "        print e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![fake gen]('image/fake1_244_300.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![errorD]('image/errorD.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![errorG]('image/errorG.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
